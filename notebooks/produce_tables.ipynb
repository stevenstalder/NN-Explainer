{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9b98d-79ed-4c39-8929-7fc543540292",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309e1be-7182-4ca8-9b48-8b21e1e5751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b35ec-62b8-4330-ba7e-5b5b5c46318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(\"../src/evaluation/results.npz\", allow_pickle=True)[\"results\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c2342-099c-4cb7-b18c-e8b4adc57191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_table()\n",
    "database_name = \"COCO\"\n",
    "model_names = [\"vgg16\", \"resnet50\"]\n",
    "methods = [\"0\", \"0.5\", \"1\", \"perfect\", \"grad_cam\", \"rise\",  \"extremal_perturbations\",  \"igos_pp\", \"rt_saliency\", \"explainer\"]\n",
    "methods_names = [\"0\", \"0.5\", \"1\", \"Ideal\", \"GradCam\", \"RISE\",  \"Fong 19\",  \"iGOS++\", \"Dabkowski 17\",  \"Explainer\", ]\n",
    "metrics = [\"d_f1\", \"c_f1\", \"acc\", \"d_IOUs\", \"c_IOU\" ,\"aucs\",'sal', 'over', 'background_c', 'mask_c']\n",
    "metrics_names = [\"Mean F1\", \"Cont F1\", \"Accuracy\", \"Discr. IOU\", \"Cont. IOU\", \"AUC\", 'Saliency', 'Accuracy', 'Background cov.', 'Object cov.']\n",
    "\n",
    "indexes = pd.MultiIndex.from_product([metrics_names, model_names], names=[\"Metric\", \"Network\"])\n",
    "\n",
    "m = np.zeros([len(metrics)*2, len(methods)])\n",
    "for i,metric in enumerate(metrics):\n",
    "    for j, method in enumerate(methods):\n",
    "        for k in [0,1]:\n",
    "            try:\n",
    "                v = results[database_name][model_names[k]][method][metric]\n",
    "                m[2*i+k,j] = \"{:.2f}\".format(np.mean(np.array([e for e in v if e is not None])))\n",
    "            except:\n",
    "                m[2*i+k,j] = np.nan\n",
    "df = pd.DataFrame(m, index=indexes, columns=methods_names)\n",
    "\n",
    "\n",
    "print(df.to_latex(index=True, escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58aec0f-63d3-4d8a-91a0-7aae7cc8b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vgg16\"\n",
    "plt.figure(figsize=(6, 4))\n",
    "x = np.arange(0.1, 1, .1)\n",
    "for method, method_name in zip(methods, methods_names):\n",
    "    if method_name in [\"0.5\", \"Ideal\"]: continue\n",
    "    if method_name in [\"0\", \"1\"]:\n",
    "        plt.plot(x, np.mean(np.array(results[database_name][model_name][method][\"a_f1s\"]), axis=0), '--', label=method_name)\n",
    "    else:\n",
    "        plt.plot(x, np.mean(np.array(results[database_name][model_name][method][\"a_f1s\"]), axis=0), label=method_name)\n",
    "plt.legend(bbox_to_anchor=(-0.03, 1.0, 1, 0.2), loc=\"lower left\", ncol=4)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.savefig(\"f1s_{}_{}.pdf\".format(database_name, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224e1cf-7fea-4c57-9aea-98d332e0e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
